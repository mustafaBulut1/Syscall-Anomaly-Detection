{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc12d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muti/Documents/GitHub/Syscall-Anomaly-Detection/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:184: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache() # Ekran kartı belleğini temizle\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcfb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SyscallDataset(Dataset):\n",
    "    def __init__(self, normal_dir, attack_dir):\n",
    "        \"\"\"\n",
    "        normal_dir: Training_Data_Master klasörünün yolu\n",
    "        attack_dir: Attack_Data_Master klasörünün yolu\n",
    "        \"\"\"\n",
    "        self.data_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Normal verileri yükle (Etiket: 0)\n",
    "        self._load_files(normal_dir, label=0)\n",
    "        \n",
    "        # Saldırı verilerini yükle (Etiket: 1)\n",
    "        self._load_files(attack_dir, label=1)\n",
    "        \n",
    "    def _load_files(self, directory, label):\n",
    "        # Klasör içindeki tüm .txt dosyalarını bulup listeye ekleriz\n",
    "        for root, _, files in os.walk(directory):\n",
    "\n",
    "            for file in sorted(files): # Dosyaları alfabetik sıralayalım ki train/test ayırırken karışmasın\n",
    "                \n",
    "                if file.endswith('.txt'):\n",
    "                    self.data_paths.append(os.path.join(root, file))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Toplam dosya sayısını döndürür\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # İstenen dosyanın yolunu al\n",
    "        file_path = self.data_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Dosyayı oku ve içindeki string sayıları integer listesine çevir\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read().strip().split()\n",
    "            # String dizisini integer dizisine dönüştür (List Comprehension)\n",
    "            # content içindeki her x için: integer yap ve +1 ekle\n",
    "            # Böylece orijinal dosyadaki '0' -> '1', '1' -> '2' olur.\n",
    "            syscall_sequence = [int(x) + 1 for x in content if x.isdigit()][:500] # İlk 500'ü al\n",
    "            #syscall_sequence = [int(x) for x in content if x.isdigit()]\n",
    "            \n",
    "        # PyTorch modelinin anlayabilmesi için listeyi Tensor'a çevir\n",
    "        # Syscall ID'leri tam sayı olduğu için dtype=torch.long kullanıyoruz\n",
    "        sequence_tensor = torch.tensor(syscall_sequence, dtype=torch.long)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return sequence_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e1cefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam  → Normal: 833 | Saldırı: 746\n",
      "Eğitim  → Normal: 666 | Saldırı: 596\n",
      "Test    → Normal: 167  | Saldırı: 150\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, random_split , Subset\n",
    "import random\n",
    "\n",
    "\n",
    "def collate_fn_pad(batch):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    for seq, label in batch:\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "        \n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    labels_tensor = torch.stack(labels).unsqueeze(1)\n",
    "    \n",
    "    return padded_sequences, labels_tensor\n",
    "\n",
    "\n",
    "\n",
    "# Tüm veriyi yükle\n",
    "full_dataset = SyscallDataset('../data/Training_Data_Master', '../data/Attack_Data_Master')\n",
    "# Sınıflara göre indeksleri ayır\n",
    "normal_indices = [i for i, l in enumerate(full_dataset.labels) if l == 0]\n",
    "attack_indices = [i for i, l in enumerate(full_dataset.labels) if l == 1]\n",
    "# Her sınıfın kendi içinde karıştır\n",
    "random.shuffle(normal_indices)\n",
    "random.shuffle(attack_indices)\n",
    "# Her sınıftan %80 eğitim, %20 test al\n",
    "def split_indices(indices, ratio=0.8):\n",
    "    cut = int(ratio * len(indices))\n",
    "    return indices[:cut], indices[cut:]\n",
    "normal_train, normal_test = split_indices(normal_indices)\n",
    "attack_train, attack_test = split_indices(attack_indices)\n",
    "# Birleştir\n",
    "train_indices = normal_train + attack_train\n",
    "test_indices  = normal_test  + attack_test\n",
    "# Subset olarak sar\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset  = Subset(full_dataset, test_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,  collate_fn=collate_fn_pad)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False, collate_fn=collate_fn_pad)\n",
    "# İstatistikleri yazdır\n",
    "normal_count = len(normal_indices)\n",
    "attack_count = len(attack_indices)\n",
    "print(f\"Toplam  → Normal: {normal_count} | Saldırı: {attack_count}\")\n",
    "print(f\"Eğitim  → Normal: {len(normal_train)} | Saldırı: {len(attack_train)}\")\n",
    "print(f\"Test    → Normal: {len(normal_test)}  | Saldırı: {len(attack_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf52bb",
   "metadata": {},
   "source": [
    "# İşlem,Nerede Yapılır?,Teknik Rolü\n",
    "Sıfırları Ekleme,collate_fn_pad,Dizileri aynı boyuta getirip matris oluşturmak.\n",
    "\n",
    "\n",
    "Sıfırları Yok Sayma,SyscallLSTM (padding_idx),Eklenen sıfırların öğrenme sürecini bozmamasını sağlamak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72bf15",
   "metadata": {},
   "source": [
    "# 1. Dosya Yollarını Belirle (src klasöründen bir üste çıkıp data'ya giriyoruz)\n",
    "normal_path = '../data/Training_Data_Master'\n",
    "attack_path = '../data/Attack_Data_Master'\n",
    "\n",
    "# 2. Dataset Sınıfını Başlat\n",
    "dataset = SyscallDataset(normal_path, attack_path)\n",
    "print(f\"Veri Setindeki Toplam Dosya (Süreç) Sayısı: {len(dataset)}\")\n",
    "\n",
    "# 3. DataLoader'ı Başlat (Veriyi 32'şerli paketler halinde GPU'ya hazırlayacak sistem)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn_pad)\n",
    "\n",
    "# 4. Sistemi Test Et (Sadece ilk batch'i çekip boyutlarına bakıyoruz)\n",
    "for sequences, labels in dataloader:\n",
    "    print(f\"Padded Batch Matris Boyutu: {sequences.shape}\") \n",
    "    print(f\"Etiket Matris Boyutu: {labels.shape}\")\n",
    "    \n",
    "    # Matrisin içindeki paddingleri (sıfırları) görmek istersen:\n",
    "    # print(sequences[0]) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9d080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Model mimarisne padding_idx ekledik çünkü 0 da bir syscal olabileceği için yanlış eğitilir 0 koyarsak.\n",
    "class SyscallLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SyscallLSTM, self).__init__()\n",
    "        \n",
    "        # 1. Katman: Embedding (Sayıları anlamlı vektörlere çevirir)\n",
    "        # padding_idx=0 diyerek 0'ların bir syscall değil dolgu olduğunu belirtiyoruz\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # 2. Katman: LSTM (Sıralı ilişkiyi ve zamanı öğrenir)\n",
    "        # batch_first=True diyerek verinin (32, Sekans_Uzunluğu) formatında olduğunu belirtiyoruz\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=2, dropout=0.2) # , num_layers=2, dropout=0.2 ekledik bize ne katar???\n",
    "        \n",
    "        # 3. Katman: Fully Connected / Linear (MLP katmanı gibi düşün)\n",
    "        # LSTM'den gelen bilgiyi tek bir sayıya (0-1 arası olasılık için) indirger\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "    \n",
    "        # 1. Hangi değerlerin padding OLMADIĞINI bul (0 olmayanlar)\n",
    "        mask = (x != 0).float().unsqueeze(-1) # [batch_size, seq_len, 1]\n",
    "        \n",
    "        # 2. Embedding ve LSTM\n",
    "        embedded = self.embedding(x)\n",
    "        out, _ = self.lstm(embedded)\n",
    "        \n",
    "        # 3. MASKELENMİŞ ORTALAMA (Kritik Nokta!)\n",
    "        # Sadece gerçek syscall'ların olduğu yerleri topla ve gerçek sayıya böl\n",
    "        out_masked = out * mask\n",
    "        out_sum = torch.sum(out_masked, dim=1)\n",
    "        mask_sum = torch.sum(mask, dim=1).clamp(min=1e-9) # 0'a bölme hatasını önle\n",
    "        \n",
    "        mean_pooled = out_sum / mask_sum # Sinyal artık seyrelmiyor!\n",
    "        \n",
    "        return self.fc(mean_pooled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c047f7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistem şu an cpu üzerinde çalışıyor.\n",
      "--- Kurulum Tamamlandı ---\n",
      "SyscallLSTM(\n",
      "  (embedding): Embedding(2000, 64, padding_idx=0)\n",
      "  (lstm): LSTM(64, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Cihaz Belirleme (GPU varsa kullan, yoksa CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Sistem şu an {device} üzerinde çalışıyor.\")\n",
    "\n",
    "# 2. Hiperparametreler\n",
    "VOCAB_SIZE = 2000 \n",
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "num_normal = 833  # Training_Data_Master içindeki dosya sayısı\n",
    "num_attack = 746  # Attack_Data_Master içindeki dosya sayısı\n",
    "\n",
    "# 3. Model, Loss ve Optimizer\n",
    "model = SyscallLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#pos_weight = torch.tensor([normal_count / attack_count]).to(device)\n",
    "weight_value = torch.tensor([1.2]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weight_value)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\"\"\"\n",
    "# Veri sayılarını manuel veya otomatik hesapla (ADFA-LD için yaklaşık oranlar)\n",
    "num_normal = 833  # Training_Data_Master içindeki dosya sayısı\n",
    "num_attack = 746  # Attack_Data_Master içindeki dosya sayısı\n",
    "# Not: Eğer sayılar farklıysa sum(1 for l in dataset.labels if l == 0) ile hesapla\n",
    "\n",
    "# Saldırı sınıfına verilecek ağırlık (Örn: 5.0 kat daha önemli gör)\n",
    "weight_value = torch.tensor([5.0]).to(device)\n",
    "#criterion = nn.BCEWithLogitsLoss(pos_weight=weight_value)\n",
    "pos_weight = torch.tensor([normal_count / attack_count]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "\n",
    "model = SyscallLSTM(2000, 64, 128, 1).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\"\"\"\n",
    "print(\"--- Kurulum Tamamlandı ---\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe9510",
   "metadata": {},
   "source": [
    "# Model eğitim kısmı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d54c570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim başlıyor (1262 örnek ile)...\n",
      "Epoch [1/40], Ortalama Hata (Loss): 0.5361\n",
      "Epoch [2/40], Ortalama Hata (Loss): 0.3402\n",
      "Epoch [3/40], Ortalama Hata (Loss): 0.2992\n",
      "Epoch [4/40], Ortalama Hata (Loss): 0.2936\n",
      "Epoch [5/40], Ortalama Hata (Loss): 0.2377\n",
      "Epoch [6/40], Ortalama Hata (Loss): 0.2119\n",
      "Epoch [7/40], Ortalama Hata (Loss): 0.2054\n",
      "Epoch [8/40], Ortalama Hata (Loss): 0.1613\n",
      "Epoch [9/40], Ortalama Hata (Loss): 0.1688\n",
      "Epoch [10/40], Ortalama Hata (Loss): 0.1884\n",
      "Epoch [11/40], Ortalama Hata (Loss): 0.3215\n",
      "Epoch [12/40], Ortalama Hata (Loss): 0.1747\n",
      "Epoch [13/40], Ortalama Hata (Loss): 0.1460\n",
      "Epoch [14/40], Ortalama Hata (Loss): 0.1338\n",
      "Epoch [15/40], Ortalama Hata (Loss): 0.1313\n",
      "Epoch [16/40], Ortalama Hata (Loss): 0.1210\n",
      "Epoch [17/40], Ortalama Hata (Loss): 0.1011\n",
      "Epoch [18/40], Ortalama Hata (Loss): 0.1222\n",
      "Epoch [19/40], Ortalama Hata (Loss): 0.1058\n",
      "Epoch [20/40], Ortalama Hata (Loss): 0.0917\n",
      "Epoch [21/40], Ortalama Hata (Loss): 0.1260\n",
      "Epoch [22/40], Ortalama Hata (Loss): 0.1066\n",
      "Epoch [23/40], Ortalama Hata (Loss): 0.0867\n",
      "Epoch [24/40], Ortalama Hata (Loss): 0.1356\n",
      "Epoch [25/40], Ortalama Hata (Loss): 0.1092\n",
      "Epoch [26/40], Ortalama Hata (Loss): 0.0875\n",
      "Epoch [27/40], Ortalama Hata (Loss): 0.1385\n",
      "Epoch [28/40], Ortalama Hata (Loss): 0.1072\n",
      "Epoch [29/40], Ortalama Hata (Loss): 0.1313\n",
      "Epoch [30/40], Ortalama Hata (Loss): 0.0902\n",
      "Epoch [31/40], Ortalama Hata (Loss): 0.0798\n",
      "Epoch [32/40], Ortalama Hata (Loss): 0.0675\n",
      "Epoch [33/40], Ortalama Hata (Loss): 0.0654\n",
      "Epoch [34/40], Ortalama Hata (Loss): 0.0568\n",
      "Epoch [35/40], Ortalama Hata (Loss): 0.0508\n",
      "Epoch [36/40], Ortalama Hata (Loss): 0.0550\n",
      "Epoch [37/40], Ortalama Hata (Loss): 0.0494\n",
      "Epoch [38/40], Ortalama Hata (Loss): 0.0702\n",
      "Epoch [39/40], Ortalama Hata (Loss): 0.0633\n",
      "Epoch [40/40], Ortalama Hata (Loss): 0.1094\n",
      "Eğitim Tamamlandı!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40 # Tüm verinin üzerinden 10 kez geçeceğiz\n",
    "print(f\"Eğitim başlıyor ({len(train_dataset)} örnek ile)...\")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # Modeli eğitim moduna al\n",
    "    total_loss = 0\n",
    "    \n",
    "    for sequences, labels in train_loader: # \n",
    "        # Verileri GPU/CPU cihazına taşı\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 1. Gradyanları sıfırla\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. İleri besleme (Forward)\n",
    "        outputs = model(sequences)\n",
    "        \n",
    "        # 3. Hatayı hesapla\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 4. Geriye yayılım (Backward)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Ağırlıkları güncelle\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Ortalama Hata (Loss): {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Eğitim Tamamlandı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840cc8d8",
   "metadata": {},
   "source": [
    "# pth ile model kaydetme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003b5f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla kaydedildi: ../models/syscall_lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Modeli kaydetmek için bir klasör oluştur (isteğe bağlı ama düzenli olur)\n",
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')\n",
    "\n",
    "# Modeli kaydet\n",
    "model_path = '../models/syscall_lstm_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(f\"Model başarıyla kaydedildi: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915772d0",
   "metadata": {},
   "source": [
    "# safetensors ile model kaydetme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f1bec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Safetensors formatında başarıyla kaydedildi: ../models/syscall_lstm_model.safetensors\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import save_file\n",
    "\n",
    "# 1. Klasörün varlığından emin ol\n",
    "if not os.path.exists('../models'):\n",
    "    os.makedirs('../models')\n",
    "\n",
    "# 2. Modelin ağırlıklarını (state_dict) al\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# 3. Safetensors olarak kaydet\n",
    "save_path = \"../models/syscall_lstm_model.safetensors\"\n",
    "save_file(state_dict, save_path)\n",
    "\n",
    "print(f\"Model Safetensors formatında başarıyla kaydedildi: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db18bb4",
   "metadata": {},
   "source": [
    "# pth ile kaydedilen modeli yükleme\n",
    "\n",
    "\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# 1. Boş mimariyi oluştur\n",
    "loaded_model = SyscallLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "\n",
    "# 2. Safetensors dosyasını oku\n",
    "tensors = load_file(\"../models/syscall_lstm_model.safetensors\")\n",
    "\n",
    "# 3. Ağırlıkları modele enjekte et\n",
    "loaded_model.load_state_dict(tensors)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Güvenli (Safetensors) model başarıyla yüklendi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acda5f41",
   "metadata": {},
   "source": [
    "# safetensors ile kaydedilen modeli yükleme\n",
    "\n",
    "\n",
    "# 1. Boş bir model nesnesi oluştur (Aynı mimari ile)\n",
    "loaded_model = SyscallLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "\n",
    "# 2. Kaydedilen ağırlıkları bu boş modele enjekte et\n",
    "loaded_model.load_state_dict(torch.load('../models/syscall_lstm_model.pth', map_location=device))\n",
    "\n",
    "# 3. Modeli test (evaluation) moduna al\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Eğitilmiş model başarıyla yüklendi ve kullanıma hazır!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63da6075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Safetensors Model Başarıyla Yüklendi ---\n",
      "\n",
      "Test edilecek toplam örnek sayısı: 317\n",
      "Tahminler yürütülüyor...\n",
      "\n",
      "==============================\n",
      "FINAL MODEL PERFORMANS RAPORU\n",
      "==============================\n",
      "Doğruluk (Accuracy): %95.90\n",
      "Kesinlik (Precision): %94.19  -> Saldırı dediklerimizin gerçeklik oranı\n",
      "Duyarlılık (Recall): %97.33     -> Gerçek saldırıları yakalama oranı\n",
      "F1-Score: 0.9574\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_file\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Güvenli Modeli Yükle\n",
    "# Not: Vocab_size ve diğer hiperparametrelerin eğitimdekiyle AYNI olması şarttır.\n",
    "loaded_model = SyscallLSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "tensors = load_file(\"../models/syscall_lstm_model.safetensors\")\n",
    "loaded_model.load_state_dict(tensors)\n",
    "loaded_model.eval() # Modeli 'Değerlendirme' moduna al (Gradyan takibini kapatır)\n",
    "\n",
    "print(\"--- Safetensors Model Başarıyla Yüklendi ---\\n\")\n",
    "\n",
    "\n",
    "print(f\"Test edilecek toplam örnek sayısı: {len(test_dataset)}\")\n",
    "\n",
    "# 3. Model Performansı Ölçme (Evaluation Loop)\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "print(\"Tahminler yürütülüyor...\")\n",
    "\n",
    "with torch.no_grad(): # Türev hesaplamayarak RAM ve hız tasarrufu sağlıyoruz\n",
    "    for sequences, labels in test_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        \n",
    "        # Modeli çalıştır\n",
    "        outputs = loaded_model(sequences)\n",
    "        \n",
    "        # Ham skoru (logit) 0.5 eşiğine göre 0 veya 1'e çevir\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# 4. Metriklerin Hesaplanması\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FINAL MODEL PERFORMANS RAPORU\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Doğruluk (Accuracy): %{accuracy*100:.2f}\")\n",
    "print(f\"Kesinlik (Precision): %{precision*100:.2f}  -> Saldırı dediklerimizin gerçeklik oranı\")\n",
    "print(f\"Duyarlılık (Recall): %{recall*100:.2f}     -> Gerçek saldırıları yakalama oranı\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"=\"*30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd45c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
